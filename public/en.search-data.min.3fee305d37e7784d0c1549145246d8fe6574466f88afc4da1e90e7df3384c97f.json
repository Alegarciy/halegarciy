[{"id":0,"href":"/posts/book-annotations/","title":"book-annotations","section":"Posts","content":"book-annotations section\n"},{"id":1,"href":"/posts/","title":"Posts","section":"Home","content":"Posts section\n"},{"id":2,"href":"/posts/sql-notes/","title":"sql-notes","section":"Posts","content":"sql-notes section\n"},{"id":3,"href":"/posts/tiny-projects/","title":"tiny-projects","section":"Posts","content":"tiny-projects section\n"},{"id":4,"href":"/posts/videos-i-like/","title":"videos I like","section":"Posts","content":"videos I like section\n"},{"id":5,"href":"/docs/section/","title":"Your Section Title","section":"Docs","content":"Section content goes here\u0026hellip;\n"},{"id":6,"href":"/posts/videos-i-like/fast-api-sebastian-ramirez-interview/","title":"FastAPI Background","section":"videos I like","content":" Sebastian Ramirez - the creator of FastAPI # Motives # This week at work we were planning to create a feature for a Python API for our event ingestions from different micro-service architecture. Given the option there was an idea to develop the back-end in Flask or other frameworks but a new framework was suggested that is called FastAPI. Then for some reason, the lead of the team proposed the migration without considering before the option (that is really bad) and a new member suggested we try out the FastAPI alternative because is more maintained at the moment.\nWhy would you create a framework # Sebastian Ramirez always thought that if you were to build a product you should always look out for the right tools, avoid \u0026ldquo;re-inventing the wheel\u0026rdquo; as many software engineers say nowadays. After three years of avoiding to build the idea, it seem like the solution was something he wished not to develop but needed it.\nFeatures that inspired FastAPI # Sebastian Ramirez had a couple of ideas on how the DX (Developer Experience) should feel for the framework based on other Python frameworks he know like DJango. Some of the features he wanted to develop were:\nAutomated documentation of the API (DJango) Swagger standardized documentation (SwaggerUI) Eliminate the code duplication (Decorator Hell) Autocomplete and auto-fill spaces (Typescript) Inspect type (Python Language) How Sebastian Ramirez avoided to re-invent the wheel was by basing his wishes of the framework and tools based on already web standards. He grabbed the standards already defined and made it so the developers had a better experience based on his own wishes to build better API frameworks.\n\u0026ldquo;Always focus on solving problems, that will be your guidance\u0026rdquo; - Sebastian Ramirez\nWhy do it in Python? # By utilizing the Python framework you could check the autocomplete with the typing, but furthermore you could use the inspect and typing feature to create the documentation (since you have the out generated typing description) and run type validation of with the same built-in function of the library like \u0026ldquo;typing\u0026rdquo; and \u0026ldquo;inspect\u0026rdquo;.\nPython is also a language for LLMs (Large Language Models) and machine learning. So for the developers that gravitate near those technologies for him didn\u0026rsquo;t seem too convenient to switch every time between technologies. With FastAPI you will automatically access the constraints of utilizing good types in python, good code practices of typed python and you will have benefits like:\nType autocomplete Input validation Output validation Typed vs Untyped Systems # Normally in Sebastian\u0026rsquo;s experience, the plugin composition and the endless ladder of decorators made it impossible for types to be well defined and cleared for the development experience. So Python users often would neglect the typing (micro seconds) it takes in exchange for a much worst without types codebase, but based on Sebastian\u0026rsquo;s perspective code efficiency and preciseness would be greatly increased if Python developers took the time to focus down in putting typing in specific places that would be require for recreating the good experience (mostly function variable declarations).\n\u0026ldquo;Making the code more intuitive, adds pleasure for the development experience\u0026rdquo; - Sebastian Ramirez\nFocus on a problem mentality # So the Sebastian\u0026rsquo;s approach to learning is always focus on a problem. Even though there is a lot of hype going around amazing ML tools and amazing ML software nowadays, there are still problems that are easy to solve waiting to be solved. Many of us focus too much on the big picture and follow trends without realizing that some of the problems you could be helping to solve are the easiest of all.\nFor Sebastian the path to learning is regardless of the background you can help build solutions. You are free to help others figure out problems and by creating that run way impact will come by itself for him, impact is only the product of a good solution. You shouldn\u0026rsquo;t focus on the outcome, but in the daily show up of creating a better solution for the problem, tempering the blade over and over until it is refined.\nEven the FastAPI framework after being utilized in many places like Meta, Nuclear Reactors and some other really important places\u0026hellip; it is still pre version 1.0. His mentality and approach to problems is always find a better way, a smarter solution a new suggestions that even though is easy or hard it will help the solution have that much impact.\nLinks: [[Coding]] [[python]]\n202409020000\n"},{"id":7,"href":"/posts/tiny-projects/starting-zettlekasten-note-system/","title":"My Zettlekasten","section":"tiny-projects","content":" Zettlekastens note taking system: First approach and review. # How the idea of note taking was conceived # At first, I started taking notes on paper since 2023 in an informal manner. I noticed that I became dependent on them, more so than I expected at first always searching for notes i didn\u0026rsquo;t record and learnings I must have forgotten because of my long-term retention capacity. Finally this year (2024), I decided to commit myself to have a formal approach on note taking.\nAs I was searching for references on my investigation, a nice reference was found of a particular devops self-thought man previously a nurse and out of passion of being a \u0026ldquo;knowledge worker\u0026rdquo; became a developer operations engineer. This man\u0026rsquo;s name is \u0026ldquo;Mischa van den Burg\u0026rdquo;. He has a zettlekasten system on his own, and I decided to follow his steps and set up my own based in some of the features he developed.\nChoosing some tools # I found myself always craving for frictionless feature, even for note taking. A frictionless feature is a tool, routine or any sort of idea that makes my life easier without putting a lot of effort on learning the habit of it. It should feel like it was always required and when you manage to do it; it should feel like it always was there.\nFor me, a frictionless feature at first was the white paper approach. The mental effort for recording new findings and information is non existent and is flexibility is impressive (adding color pencils feels great!). But the white paper approach really lacked in the recovering mechanism. For this same reason I manage to create a better automatized approach using Neovim fuzzy finder features + Obsidian\u0026rsquo;s graph viewer.\nNeovim is a great IDE for development mostly but can be configure to search between notes and making great experience for writing code. Since I have a developer background I decided to create a \u0026ldquo;Neovim note taking system\u0026rdquo; approach based on what Mischa van den Burg suggested himself. Obsidian was a note taking system that has interesting graphical plugins and visualizations, that will provide more aesthetic note visualizations.\nRemoving friction for the note taking system # Once I had figured out which tools would be useful for the system, I had to reduce as much friction as possible. Friction for me, is the antagonist of proactivity. Reducing effort contributes to creating action, by facilitating the person to not stall through tedious routines.\nA easy technical solution for reducing the undesirable friction was to create a serious of small automatization around the interaction specifically of creating notes. The biggest gap I thought needed to be attended as soon as possible was the recording new findings mechanism. Opening an application is a major friction point for me as a user, so creating a shortcut for it that will create a note structure with an specific unique identifier per note is valuable.\nAs a solution, I manage to investigate a proper automatized small system with bash files. For this system, my previous experience had thought me that many bash files tend to entropy real quick. Given that a good solution, most be maintainable and understandable for a long time, I decided to create a personal folder for all dotfiles solution. A dotfile based on what is posted on Github dotfile topic it is:\nLegend goes, that dotfiles were invented when ls used to skip files and directories starting with a . (dot). As a result, files that begin with such a character were not shown when listing using ls — i.e. it was a \u0026ldquo;hidden\u0026rdquo; file. Since dotfiles are ususually user-specific, a predestined place for them is the $HOME directory. Commonly used files are for example: .bashrc, .zshrc or .vimrc.\nDefining a documentation strategy # Taking notes is to live with intention - Mischa van den Burg\nI am a forgetful person, and I am in a moment in my life were ideas are a big part of me. This quote above, resonated with how i felt for the longest time, forgetting was a painful act in itself since valuable thoughts you cherish suddenly banish and you don\u0026rsquo;t notice them when they go away. I want to record thoughts, they don\u0026rsquo;t need to have an specific structure or make much sense but I want to be the craftsman of my empire of ideas.\nThe PARA method: An informal idea of indexing logs # For the PARA methods, it is a simple note taking system, that creates a couple of concepts around how files should be ordered into a limited categories of folders. This folder are the (P)rojects, (A)reas, (R)esources, (A)rchives. Each of them has a use:\nProjects: \u0026ldquo;A project is a sequence of tasks you need to accomplish in order to achieve a certain outcome - David Allan\u0026rdquo; (3 months - 12 months)\nAreas: It involves ongoing engagements. It places a particular important role in your life. Are areas particularly important to your life like health, sports, family, \u0026hellip;\nResources: Is a collection of information, that you expect to be useful. It can be hobbies, investigations, interests, \u0026hellip;\nArchive: Searching for notes, old notes will appear and you make connections. This is information can be logged as \u0026ldquo;old\u0026rdquo;, but could appear on a search for a helping hand some day.\nWhat is the origin of a log (small story) # A log started life as a lump of wood such as you might throw on a fire. And it still is - sometimes. When sailors wanted to know how fast they were going, they would throw over the stern a log tied to a bit of string with regularly spaced knots in it. By counting the number of knots that went out in a fixed time, they would know their speed - in knots, of course. A navigator would want to have a regular record of this speed, so that he could calculate how fast the ship was travelling than thus roughly where he was. So the speed was written down, initially on a slate but later in a book, which, since it recorded the log measurements, was called the log. - By Alec Cawley\nLinks: [[Notes]] [[Research]]\nMy Neovim Zettelkasten - Mischa van den Burg\nDotfiles - Rob Muhlestein (rwxrob)\nGithub dotfiles\nDotfiles Webpro - Lars Kappert\n202408101453\n"},{"id":8,"href":"/posts/book-annotations/sql-cookbook-favorites/","title":"SQL Cookbook Favorites","section":"book-annotations","content":" SQL Cook Book Notes: # Chapter 1: Retrieving Records # For initializing the project run the following command:\npsql -U postgres -h localhost -p 5432 -d postgres -f init_setup.sql 1.6 Referencing and Aliased Column in the WHERE Clause # This is a interesting example because referencing aliased columns will fail unless you wrap it around another query:\nselect * from ( select sal as salary, comm as commission from emp ) x where salary \u0026lt; 5000 This works because the order of clauses is the next one:\nFROM CLAUSE SELECT CLAUSE WHERE CLAUSE This well lead to new concepts:\nAggregated Functions Scalar Subqueries Windowing functions Aliases 1.10 Returning n Random Records from a Table # This is an interesting example for creating programs with different data executions samples:\nselect ename, job from emp order by random() limit 5 The ORDER BY clause can accept a function\u0026rsquo;s return value and use it to change the order of the result set.\nFUNCTION EXAMPLE -\u0026gt; random() ORDER CLAUSE LIMIT CLAUSE Chapter 2: Sorting Query Results # 2.2 Sorting multiple fields # The order of PRECEDENCE in ORDER BY is from left to right\nThis means that groups are first form for the sorted [select_list_element_pos0] and then evaluate the other list items moving forward. (e.g)\nselect empno, deptno, sal, ename, job from emp order by deptno , sal desc In this case, the order would be priority 0 deptno and then sort those \u0026ldquo;groups\u0026rdquo; by sal.\nYou are generally permitted to order by a column not in the SELECT list, but to do so you must explicitly name the column. However, if you are using GROUP BY or DISTINCT in your query, you cannot order by columns that are not in the SELECT list.\n2.5 Dealing with NULL while sorting # Normally if you are not using oracle the standard solution is to create an extra column:\nselect ename, sal, comm, is_null from ( select ename, sal, comm, case when comm is null then 0 else 1 end as is_null from emp ) x order by is_null desc, comm desc 2.6 Sorting on a Data-Dependent Key # You can sort by a data dependent key by applying conditionals in the ORDER CLAUSE:\nselect ename, sal, job, comm from emp order by ( case when job=\u0026#39;SALESMAN\u0026#39; then comm else sal end ) Chapter 3: Working with Multiple Tables # 3.1 Stacking one row set atop another # This is an interesting analogy where the UNION ALL clause is compared to stacking tables by its shared datatype.\nUNION ALL: will allow repetition UNION: will filter out repeated results As with all set operations, the items in all the SELECT lists must match in number and data type.\nLook out for performance improvements on any de-duplication process:\nBefore using DISTINCT you need to ask yourself why do you need distinct to deduplicate a dataset... and the answer is almost always because of a bad join, missing constraints and/or dirty data. 3.2 Combining Related Rows # Is the basics of the inner join, but also i want to highlight how are different representations of it and the Cartesian product:\nselect count(*) from dept d , emp e -- cartesian product: 56 select count(*) from emp e inner join dept d on e.deptno = d.deptno -- cartesian product: 14 when the department matched select count(*) from dept d, emp e where d.deptno = e.deptno -- cartesian product: 14 this is the \u0026#39;equi-join\u0026#39; 3.4 Retrieving value from on table that do not exist in another # In Postgresql you have the except operator:\nselect deptno from dept except select deptno from emp 3.8 Identifying and Avoiding Cartesian Products # For this section, most of the SQL i will work with, will already be created so this process of analyzing and depicting the Cartesian products should be apply whenever I see a table.\nA couple of rules for cardinality:\nGenerally, to avoid a Cartesian product, you would apply the n-1 rule where n represents the number of tables in the FROM clause and n-1 represents the minimun number of joins necessary to avoid a Cartesian product. Depending on what the keys and join columns in your tables are, you may very well need more than n-1 joins but n-1 is a good place to start when writing queries. Cartesian Product Usefulness:\nWhen used properly, Cartesian products can be useful. Common uses of Cartesian products include transposing or pivoting (and unpivoting) a result set, generating a sequence of values, and mimicking a loop (although the last may also be accomplished using a recursive CTE).\n3.9 Performing Join When Using Aggregates # I believe this is one of the trickiest parts of building good data and is avoiding at ALL COST repetition while creating joins and aggregates with repeated data.\nAn example case of this is whenever you in a Cartesian product have a repeated row say two times the row in which ONE employee has salary. Then if you do an aggregate of the salary it will counts two times that person salary.\nIn this kind of cases the solution that is viable is to create a grouping before it like a view or a nested table on the query that will make the salaries unique for the inner join (an aggregation before the real aggregation).\nExample 01: In this example we are making sure the bonus row is aggregated before the aggregation of the salary otherwise we will aggregate the bonus correctly but the salary would be doubled.\nselect x.deptno, sum(x.sal), sum(x.bonus) from (\tselect e.empno, e.sal, e.deptno, sum(e.sal * case when eb.\u0026#34;type\u0026#34; = 1 then .1 when eb.\u0026#34;type\u0026#34; = 2 then .2 else .3 end ) as bonus from emp e, emp_bonus eb where e.empno = eb.empno and e.deptno = 10 group by e.empno , e.sal, e.deptno ) x group by deptno As an alternative you can create the new table because in the previous example we are creating the column and the grouping by removing duplicates:\nselect d.deptno, d.total_sal, sum(e.sal * case when eb.\u0026#34;type\u0026#34; = 1 then .1 when eb.\u0026#34;type\u0026#34; = 2 then .2 else .3 end ) as bonus from emp e, emp_bonus eb, ( select deptno, sum(sal) as total_sal from emp where deptno = 10 group by deptno ) d where e.deptno = d.deptno and e.empno = eb.empno group by d.deptno, d.total_sal 3.10: Performing Outer Joins When Using Aggregates # This is the same example but assuming you there are people with NULL bonuses so on the left outer join and the case you need to be aware of that:\nselect x.deptno, sum(x.sal), sum(x.bonus) from ( select e.empno, e.sal, e.deptno, sum( e.sal * case when eb.\u0026#34;type\u0026#34; = 1 then .1 when eb.\u0026#34;type\u0026#34; = 2 then .2 when eb.\u0026#34;type\u0026#34; = 3 then .3 else 0 end ) as bonus from emp e left outer join emp_bonus eb on eb.empno = e.empno inner join dept d on e.deptno = d.deptno where d.deptno = 10 group by e.empno , e.sal, e.deptno ) x group by deptno Chapter 4: Inserting, Updating, and Deleting # 4.1 Inserting records (tips) # You can do multiple inserts at the same time:\n/* multi row insert */ insert into dept (deptno,dname,loc) values (1,\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;), (2,\u0026#39;B\u0026#39;,\u0026#39;C\u0026#39;) Also if you want to insert a column default value you will do:\n4.2 Inserting Default Values # All brands support the use of the DEFAULT keyword.\ninsert into D values (values) Also for tables with default values in multiple columns excluding the column will mean the brand of database will automatically insert the default value for that column.\n4.3 Overriding a default value with NULL # /* table: create table (id integer default 0, foo varchar(20)) insert into d (id,foo) values (null, \u0026#39;Brighten\u0026#39;) 4.4 Copying the rows from one table into another (Very Useful) # So far one of the most useful commands for data recovery and upgrading existing tables:\ninsert into dept_east (deptno, dname, loc) select deptno, dname, loc from dept where loc in (\u0026#39;NEW YORK\u0026#39;, \u0026#39;BOSTON\u0026#39;) 4.5 Copying a Table Definition (Very Useful) # You want to create a table having the same set of column as the existing columns, but no rows:\ncreate table dept_2 as select * from dept where 1=0 When using CTAS - Create Table as Select, all rows from your query will be used to populate the new table you are creating unless you specify a false condition in the WHERE clause.\n4.8 Modifying Records in a Table # Use the UPDATE statement to modify existing rows in a database table. For example:\nupdate emp set sal = sal*1.10 where deptno = 20 4.9 Updating when corresponding rows exists # update emp set sal=sal*1.10 where empno in (select empno from emp_bonus) 4.10 Updating with Values from Another Table # In PostgreSQL you can do the next method to conveniently update joining with another table:\nupdate emp set sal = ns.sal, comm = ns.sal/2 from new_sal ns where ns.deptno = emp.deptno 4.15 Deleting Referential Integrity Violations # Using the NOT IN alternative I find it more readable\ndelete from emp where deptno not in (select deptno from dept) 4.17 Deleting Records Referenced from Another Table # Using a subquery and the aggregation functions like count you can find the departments with three or more accidents. Then delete all employees working in those departments:\ndelete from emp where deptno in ( select deptno from dept_accidents group by deptno having count(*) \u0026gt;= 3 ) Chapter 5: Metadata Queries # 5.1 Listing Tables in a Schema # In postgres the information of the database is done through the table INFORMATION_SCHEMA.TABLES:\nselect table_name from information_schema.tables where table_schema = \u0026#39;SMEAGOL\u0026#39; So basically tables have this mechanism of exposing their own information about themselves in a manner of tables and views just as other information is exposed.\n5.2 Listing Table\u0026rsquo;s Columns # In postgres the information of the database is done through the table INFORMATION_SCHEMA.COLUMNS:\nselect column_name, data_type, ordinal_position from information_schema.columns where table_schema = \u0026#39;SMEAGOL\u0026#39; and table_name = \u0026#39;EMP\u0026#39; 5.3 Listing Indexed Columns for a Table # select a.tablename, a.indexname, b.column_name from pg_catalog.pg_indexes a, information_schema.columns b where a.schemaname = \u0026#39;SMEAGOL\u0026#39; and a.tablename = b.table_name When it comes to queries, it\u0026rsquo;s important to know what columns are/aren\u0026rsquo;t indexed. Indexes can provide good performance for queries against columns that are frequently used in filters and that are fairly selective. Indexes are also useful when joining between tables.\nLinks:\nDocumentations: Postgres: String Function\nArticles: Reddit: Is SELECT DISTINCT really that bad?\nVideos: Cartesian Product\n202411070009\n"},{"id":9,"href":"/posts/sql-notes/transactions/","title":"Transactions","section":"sql-notes","content":" 📌 Guide: Writing Responsible Transactions in PostgreSQL # A transaction is a sequence of SQL statements executed as a single unit of work. It ensures that all statements within it either succeed completely or fail together, maintaining ACID properties (Atomicity, Consistency, Isolation, Durability).\n🏁 1. Starting a Transaction Properly # ✅ Basic Transaction Syntax # BEGIN; -- Start a transaction -- Your SQL statements here COMMIT; -- Save changes permanently OR\nBEGIN; -- Start a transaction -- Your SQL statements here ROLLBACK; -- Undo changes if something goes wrong 🚦 2. Example: Safe Insert and Update # 🛠 Scenario: Banking System - Transferring Money # Imagine a money transfer between two accounts:\nDeduct $100 from Account A. Add $100 to Account B. If either fails, rollback everything. ✅ Correct Approach Using Transactions # BEGIN; -- Start transaction -- Deduct from sender UPDATE accounts SET balance = balance - 100 WHERE id = 1; -- Add to receiver UPDATE accounts SET balance = balance + 100 WHERE id = 2; -- If everything is successful, commit COMMIT; If both statements succeed, the transaction is committed. If any step fails, use ROLLBACK; instead of COMMIT;. 🚨 3. Handling Errors with ROLLBACK # If something goes wrong in the transaction (e.g., insufficient funds), we can undo all changes.\n❌ Bad Example (No Rollback) # BEGIN; UPDATE accounts SET balance = balance - 100 WHERE id = 1; -- Oops! Next line fails due to constraint violation UPDATE accounts SET balance = balance + 100 WHERE id = 999; -- Invalid ID COMMIT; -- 💥 ERROR: The first update is already applied! The first update succeeded, but the second failed. Account A lost $100, but Account B never received it! ❌ ✅ Correct Way (Using ROLLBACK) # BEGIN; UPDATE accounts SET balance = balance - 100 WHERE id = 1; -- Simulate an error (e.g., invalid account ID) UPDATE accounts SET balance = balance + 100 WHERE id = 999; -- If something goes wrong, rollback everything ROLLBACK; Now nothing is applied if an error occurs.\n🔄 4. Using Savepoints for Partial Rollbacks # Sometimes, you want to partially undo changes instead of rolling back the entire transaction. Savepoints help with that.\n✅ Example: Multiple Updates with Savepoints # BEGIN; SAVEPOINT sp1; UPDATE accounts SET balance = balance - 100 WHERE id = 1; SAVEPOINT sp2; UPDATE accounts SET balance = balance + 100 WHERE id = 2; -- Oops! Something goes wrong ROLLBACK TO SAVEPOINT sp2; -- Undo only the last change -- Continue transaction COMMIT; Savepoints allow rolling back only part of the transaction instead of everything. Useful when dealing with batch processing. ⏳ 5. Avoiding Deadlocks and Performance Issues # Deadlocks occur when two transactions wait for each other to release locks. To avoid them:\n✅ Best Practices # Access tables in the same order in all transactions. Keep transactions short to avoid holding locks too long. Use FOR UPDATE to lock rows explicitly: SELECT * FROM accounts WHERE id = 1 FOR UPDATE; This prevents another transaction from modifying the same row simultaneously.\n🎯 6. Using Isolation Levels # PostgreSQL provides four transaction isolation levels to control how transactions interact.\n💮 Isolation Levels # Level Dirty Reads Non-Repeatable Reads Phantom Reads READ UNCOMMITTED ✅ Allowed ✅ Allowed ✅ Allowed READ COMMITTED (default) ❌ Not Allowed ✅ Allowed ✅ Allowed REPEATABLE READ ❌ Not Allowed ❌ Not Allowed ✅ Allowed SERIALIZABLE ❌ Not Allowed ❌ Not Allowed ❌ Not Allowed ✅ Example: Setting an Isolation Level # SET TRANSACTION ISOLATION LEVEL REPEATABLE READ; BEGIN; -- Your SQL statements here COMMIT; Use REPEATABLE READ for consistency in reports. Use SERIALIZABLE to avoid concurrency issues but expect performance trade-offs. 🏆 7. Best Practices for Responsible Transactions # ✅ Keep transactions short: Avoid holding locks longer than necessary.\n✅ Always use ROLLBACK for error handling: Prevent incomplete changes.\n✅ Use SAVEPOINT for partial rollbacks: Avoid restarting entire transactions.\n✅ Lock rows explicitly if updating the same records in multiple transactions.\n✅ Test transactions with a ROLLBACK first before applying COMMIT.\n🌟 Final Example: A Well-Structured Transaction # BEGIN; -- Step 1: Deduct funds UPDATE accounts SET balance = balance - 100 WHERE id = 1; -- Step 2: Savepoint before updating receiver SAVEPOINT before_receiver_update; -- Step 3: Add funds to the receiver UPDATE accounts SET balance = balance + 100 WHERE id = 2; -- Step 4: Check if everything is good, commit COMMIT; If anything fails before COMMIT, simply:\nROLLBACK; Or, if only the last step fails:\nROLLBACK TO SAVEPOINT before_receiver_update; ✅ Conclusion # With this guide, you now know how to write safe, responsible transactions in PostgreSQL to:\nPrevent data corruption. Handle errors properly. Avoid deadlocks and performance issues. Use savepoints for granular control. Let me know if you want a more specific case covered! 🚀\nLinks # AUTOCOMMIT;COMMIT;ROLLBACK "},{"id":10,"href":"/posts/tiny-projects/github-profile/","title":"Github Profile","section":"tiny-projects","content":" Github Profile # Motives # I want to be able to make my Github page profile better looking, have a nice feel when people investigate my profile and projects. I want it to feel elegant and minimalistic, without too much overhead you have to go through. I watched a couple of profiles that implemented this ideas and I liked the approach enough to wanting to do it.\nReferences \u0026amp; Observations # Languages and Tools Section because of Dropdown is cool. Profile Gautamkrishnar Project Development # This is a project that won\u0026rsquo;t take more than 2 weeks, so the t-shirt size I would say feels like a XS. I notice that the README.md files could be scripted and filled with information on them by creating cron jobs of actions or even trigger actions inside Github. That means there is a lot of programmability you can add to your profile, that will extend the profile view from a basic markup project to a bigger project to showcase your creativity. (This was discovered specifically in the Simon Willison\u0026rsquo;s article).\nLinks # [[Project]] [[Career]] [[public-university-repositories]] Github Profile Managing your profile README awesome-github-profile-readme Simon Willison\u0026rsquo;s updating profile README 202408151232\n"}]